{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nibabel as nib\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K \n",
    "\n",
    "import util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HOME_DIR = \"./data/BraTS-Data/\"\n",
    "DATA_DIR = HOME_DIR\n",
    "\n",
    "def load_case(image_nifty_file, label_nifty_file):\n",
    "    image = np.array(nib.load(image_nifty_file).get_fdata())\n",
    "    label = np.array(nib.load(label_nifty_file).get_fdata())\n",
    "    \n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image, label = load_case(DATA_DIR + \"imagesTr/BRATS_003.nii.gz\", DATA_DIR + \"labelsTr/BRATS_003.nii.gz\")\n",
    "print(image.shape)\n",
    "print(label.shape)\n",
    "image = util.get_labeled_image(image, label)\n",
    "\n",
    "util.plot_image_grid(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image, label = load_case(DATA_DIR + \"imagesTr/BRATS_003.nii.gz\", DATA_DIR + \"labelsTr/BRATS_003.nii.gz\")\n",
    "util.visualize_data_gif(util.get_labeled_image(image, label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sub_volume(image, label, \n",
    "                   orig_x = 240, orig_y = 240, orig_z = 155, \n",
    "                   output_x = 160, output_y = 160, output_z = 16,\n",
    "                   num_classes = 4, max_tries = 1000, \n",
    "                   background_threshold=0.95):\n",
    "    X = None\n",
    "    y = None\n",
    "\n",
    "    \n",
    "    tries = 0\n",
    "    \n",
    "    while tries < max_tries:\n",
    "        start_x = np.random.randint(0 , orig_x - output_x + 1)\n",
    "        start_y = np.random.randint(0 , orig_y - output_y + 1)\n",
    "        start_z = np.random.randint(0 , orig_z - output_z + 1)\n",
    "\n",
    "        y = label[start_x: start_x + output_x,\n",
    "                  start_y: start_y + output_y,\n",
    "                  start_z: start_z + output_z]\n",
    "        \n",
    "        y = keras.utils.to_categorical(y, num_classes = num_classes)\n",
    "\n",
    "        bgrd_ratio = np.sum(y[:,:,:,0]) / (output_x * output_y * output_z)\n",
    "\n",
    "        tries += 1\n",
    "\n",
    "        if bgrd_ratio < background_threshold:\n",
    "\n",
    "            X = np.copy(image[start_x: start_x + output_x,\n",
    "                              start_y: start_y + output_y,\n",
    "                              start_z: start_z + output_z, :])\n",
    "            \n",
    "            X = np.moveaxis(X,3,0)\n",
    "\n",
    "            y = np.moveaxis(y,3,0)\n",
    "\n",
    "            y = y[1:, :, :, :]\n",
    "    \n",
    "            return X, y\n",
    "\n",
    "    print(f\"Tried {tries} times to find a sub-volume. Giving up...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(3)\n",
    "\n",
    "image = np.zeros((4, 4, 3, 1))\n",
    "label = np.zeros((4, 4, 3))\n",
    "for i in range(4):\n",
    "    for j in range(4):\n",
    "        for k in range(3):\n",
    "            image[i, j, k, 0] = i*j*k\n",
    "            label[i, j, k] = k\n",
    "\n",
    "print(\"image:\")\n",
    "for k in range(3):\n",
    "    print(f\"z = {k}\")\n",
    "    print(image[:, :, k, 0])\n",
    "print(\"\\n\")\n",
    "print(\"label:\")\n",
    "for k in range(3):\n",
    "    print(f\"z = {k}\")\n",
    "    print(label[:, :, k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_image, sample_label = get_sub_volume(image, \n",
    "                                            label,\n",
    "                                            orig_x=4, \n",
    "                                            orig_y=4, \n",
    "                                            orig_z=3,\n",
    "                                            output_x=2, \n",
    "                                            output_y=2, \n",
    "                                            output_z=2,\n",
    "                                            num_classes = 3)\n",
    "\n",
    "print(\"Sampled Image:\")\n",
    "for k in range(2):\n",
    "    print(\"z = \" + str(k))\n",
    "    print(sample_image[0, :, :, k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Sampled Label:\")\n",
    "for c in range(2):\n",
    "    print(\"class = \" + str(c))\n",
    "    for k in range(2):\n",
    "        print(\"z = \" + str(k))\n",
    "        print(sample_label[c, :, :, k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image, label = load_case(DATA_DIR + \"imagesTr/BRATS_001.nii.gz\", DATA_DIR + \"labelsTr/BRATS_001.nii.gz\")\n",
    "X, y = get_sub_volume(image, label)\n",
    "util.visualize_patch(X[0, :, :, :], y[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize(image):\n",
    "\n",
    "    standardized_image = np.zeros(image.shape)\n",
    "\n",
    "    for c in range(image.shape[0]):\n",
    "        for z in range(image.shape[3]):\n",
    "            image_slice = image[c,:,:,z]\n",
    "\n",
    "            centered = image_slice - np.mean(image_slice)\n",
    "            \n",
    "            centered_scaled = centered / np.std(centered)\n",
    "\n",
    "            standardized_image[c, :, :, z] = centered_scaled\n",
    "\n",
    "\n",
    "    return standardized_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_norm = standardize(X)\n",
    "print(\"standard deviation for a slice should be 1.0\")\n",
    "print(f\"stddv for X_norm[0, :, :, 0]: {X_norm[0,:,:,0].std():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "util.visualize_patch(X_norm[0, :, :, :], y[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_class_dice_coefficient(y_true, y_pred, axis=(0, 1, 2), \n",
    "                                  epsilon=0.00001):\n",
    "\n",
    "    dice_numerator = 2 * np.sum(y_true * y_pred, axis = axis) + epsilon\n",
    "    dice_denominator = K.sum(y_true,axis= axis) + K.sum(y_pred, axis= axis) + epsilon\n",
    "    dice_coefficient = dice_numerator / dice_denominator\n",
    "    \n",
    "\n",
    "\n",
    "    return dice_coefficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tensor_to_array(array_value):\n",
    "    return array_value.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess =tf.compat.v1.keras.backend.get_session()\n",
    "#  K.get_session()\n",
    "with sess.as_default() as sess:\n",
    "    pred = np.expand_dims(np.eye(2), -1)\n",
    "    label = np.expand_dims(np.array([[1.0, 1.0], [0.0, 0.0]]), -1)\n",
    "\n",
    "    print(\"pred:\")\n",
    "    print(pred[:, :, 0])\n",
    "    print(\"label:\")\n",
    "    print(label[:, :, 0])\n",
    "\n",
    "    dc = single_class_dice_coefficient(pred, label,epsilon=1)\n",
    "    print('dc: ', dc)\n",
    "    print(\"{:.2f}\".format(tensor_to_array(dc)))\n",
    "\n",
    "    print(\"\\n\")\n",
    "\n",
    "    pred = np.expand_dims(np.eye(2), -1)\n",
    "    label = np.expand_dims(np.array([[1.0, 1.0], [0.0, 1.0]]), -1)\n",
    "\n",
    "    print(\"pred:\")\n",
    "    print(pred[:, :, 0])\n",
    "    print(\"label:\")\n",
    "    print(label[:, :, 0])\n",
    "\n",
    "    dc = single_class_dice_coefficient(pred, label,epsilon=1)\n",
    "    print('dc:', dc)\n",
    "    print(\"{:.2f}\".format(tensor_to_array(dc)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_coefficient(y_true, y_pred, axis=(1, 2, 3), \n",
    "                     epsilon=0.00001):\n",
    "\n",
    "    dice_numerator = 2 * K.sum(y_true * y_pred , axis = axis) + epsilon\n",
    "    dice_denominator = K.sum(y_true, axis = axis ) + K.sum(y_pred, axis = axis) + epsilon\n",
    "    dice_coefficient = K.mean(dice_numerator/dice_denominator)\n",
    "    \n",
    "\n",
    "    return dice_coefficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess =tf.compat.v1.keras.backend.get_session()\n",
    "# sess = K.get_session()\n",
    "with sess.as_default() as sess:\n",
    "    pred = np.expand_dims(np.expand_dims(np.eye(2), 0), -1)\n",
    "    label = np.expand_dims(np.expand_dims(np.array([[1.0, 1.0], [0.0, 0.0]]), 0), -1)\n",
    "\n",
    "\n",
    "    print(\"pred:\")\n",
    "    print(pred[0, :, :, 0])\n",
    "    print(\"label:\")\n",
    "    print(label[0, :, :, 0])\n",
    "\n",
    "    dc = dice_coefficient(label, pred, epsilon=1)\n",
    "    print(\"{:.4f}\".format(tensor_to_array(dc)))\n",
    "\n",
    "    print(\"\\n\")\n",
    "\n",
    "    pred = np.expand_dims(np.expand_dims(np.eye(2), 0), -1)\n",
    "    label = np.expand_dims(np.expand_dims(np.array([[1.0, 1.0], [0.0, 1.0]]), 0), -1)\n",
    "\n",
    "\n",
    "    print(\"pred:\")\n",
    "    print(pred[0, :, :, 0])\n",
    "    print(\"label:\")\n",
    "    print(label[0, :, :, 0])\n",
    "\n",
    "    dc = dice_coefficient(pred, label,epsilon=1)\n",
    "    print(\"{:.4f}\".format(tensor_to_array(dc)))\n",
    "    print(\"\\n\")\n",
    "\n",
    "\n",
    "    pred = np.zeros((2, 2, 2, 1))\n",
    "    pred[0, :, :, :] = np.expand_dims(np.eye(2), -1)\n",
    "    pred[1, :, :, :] = np.expand_dims(np.eye(2), -1)\n",
    "    \n",
    "    label = np.zeros((2, 2, 2, 1))\n",
    "    label[0, :, :, :] = np.expand_dims(np.array([[1.0, 1.0], [0.0, 0.0]]), -1)\n",
    "    label[1, :, :, :] = np.expand_dims(np.array([[1.0, 1.0], [0.0, 1.0]]), -1)\n",
    "\n",
    "    print(\"pred:\")\n",
    "    print(\"class = 0\")\n",
    "    print(pred[0, :, :, 0])\n",
    "    print(\"class = 1\")\n",
    "    print(pred[1, :, :, 0])\n",
    "    print(\"label:\")\n",
    "    print(\"class = 0\")\n",
    "    print(label[0, :, :, 0])\n",
    "    print(\"class = 1\")\n",
    "    print(label[1, :, :, 0])\n",
    "\n",
    "    dc = dice_coefficient(pred, label,epsilon=1)\n",
    "    print(\"{:.4f}\".format(tensor_to_array(dc)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def soft_dice_loss(y_true, y_pred, axis=(1, 2, 3), \n",
    "                   epsilon=0.00001):\n",
    "\n",
    "    dice_numerator = 2 * K.sum(y_true * y_pred , axis= axis) + epsilon\n",
    "    dice_denominator = K.sum(y_true ** 2, axis= axis) + K.sum(y_pred ** 2 , axis = axis) + epsilon\n",
    "    dice_loss = 1 - K.mean(dice_numerator / dice_denominator)\n",
    "\n",
    "\n",
    "    return dice_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = util.unet_model_3d(loss_function=soft_dice_loss, metrics=[dice_coefficient])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = HOME_DIR + \"processed/\"\n",
    "with open(base_dir + \"config.json\") as json_file:\n",
    "    config = json.load(json_file)\n",
    "train_generator = util.VolumeDataGenerator(config[\"train\"], base_dir + \"train/\", batch_size=3, dim=(160, 160, 16), verbose=0)\n",
    "valid_generator = util.VolumeDataGenerator(config[\"valid\"], base_dir + \"valid/\", batch_size=3, dim=(160, 160, 16), verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(HOME_DIR + \"model_pretrained.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "util.visualize_patch(X_norm[0, :, :, :], y[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_norm_with_batch_dimension = np.expand_dims(X_norm, axis=0)\n",
    "patch_pred = model.predict(X_norm_with_batch_dimension)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.5\n",
    "\n",
    "patch_pred[patch_pred > threshold] = 1.0\n",
    "patch_pred[patch_pred <= threshold] = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Patch and ground truth\")\n",
    "util.visualize_patch(X_norm[0, :, :, :], y[2])\n",
    "plt.show()\n",
    "print(\"Patch and prediction\")\n",
    "util.visualize_patch(X_norm[0, :, :, :], patch_pred[0, 2, :, :, :])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_class_sens_spec(pred, label, class_num):\n",
    "\n",
    "    class_pred = pred[class_num]\n",
    "    class_label = label[class_num]\n",
    "\n",
    "\n",
    "    tp = np.sum( (class_pred == 1) * (class_label == 1))\n",
    "\n",
    "    tn = np.sum( (class_pred == 0) * (class_label == 0))\n",
    "    \n",
    "    fp = np.sum( (class_pred == 1) * (class_label == 0))\n",
    "    \n",
    "    fn = np.sum( (class_pred == 0) * (class_label == 1))\n",
    "\n",
    "    sensitivity = tp / (tp + fn)\n",
    "    specificity = tn / (tn + fp)\n",
    "\n",
    "\n",
    "    return sensitivity, specificity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "\n",
    "df = pd.DataFrame({'y_test': [1,1,0,0,0,0,0,0,0,1,1,1,1,1],\n",
    "                   'preds_test': [1,1,0,0,0,1,1,1,1,0,0,0,0,0],\n",
    "                   'category': ['TP','TP','TN','TN','TN','FP','FP','FP','FP','FN','FN','FN','FN','FN']\n",
    "                  })\n",
    "\n",
    "display(df)\n",
    "pred = np.array( [df['preds_test']])\n",
    "label = np.array( [df['y_test']])\n",
    "\n",
    "sensitivity, specificity = compute_class_sens_spec(pred, label, 0)\n",
    "print(f\"sensitivity: {sensitivity:.4f}\")\n",
    "print(f\"specificity: {specificity:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensitivity, specificity = compute_class_sens_spec(patch_pred[0], y, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sens_spec_df(pred, label):\n",
    "    patch_metrics = pd.DataFrame(\n",
    "        columns = ['Edema', \n",
    "                   'Non-Enhancing Tumor', \n",
    "                   'Enhancing Tumor'], \n",
    "        index = ['Sensitivity',\n",
    "                 'Specificity'])\n",
    "    \n",
    "    for i, class_name in enumerate(patch_metrics.columns):\n",
    "        sens, spec = compute_class_sens_spec(pred, label, i)\n",
    "        patch_metrics.loc['Sensitivity', class_name] = round(sens,4)\n",
    "        patch_metrics.loc['Specificity', class_name] = round(spec,4)\n",
    "\n",
    "    return patch_metrics\n",
    "df = get_sens_spec_df(patch_pred[0], y)\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image, label = load_case(DATA_DIR + \"imagesTr/BRATS_003.nii.gz\", DATA_DIR + \"labelsTr/BRATS_003.nii.gz\")\n",
    "pred = util.predict_and_viz(image, label, model, .5, loc=(130, 130, 77)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "whole_scan_label = keras.utils.to_categorical(label, num_classes = 4)\n",
    "whole_scan_pred = pred\n",
    "\n",
    "whole_scan_label = np.moveaxis(whole_scan_label, 3 ,0)[1:4]\n",
    "whole_scan_pred = np.moveaxis(whole_scan_pred, 3, 0)[1:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "whole_scan_df = get_sens_spec_df(whole_scan_pred, whole_scan_label)\n",
    "\n",
    "print(whole_scan_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "570feb405e2e27c949193ac68f46852414290d515b0ba6e5d90d076ed2284471"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
